{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jYPrR2lprpDe"
   },
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uyL_MsBMrioC"
   },
   "source": [
    "#### This project is made using the framekwork **Scrapy v1.6.0**  to scrape data from two main websites: *Hespress* & Hibapress. \n",
    "##### These data relate primarily to existing articles in each of the two websites mentioned. \n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i3Nz1YqNspc_"
   },
   "source": [
    "# Purpose of the project: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CR4pziFustVU"
   },
   "source": [
    "### The main purpose of this project is to scrape articles existing in theses two websites: *Hespress* & Hibapress. \n",
    "  \n",
    "\n",
    "\n",
    "> The process of scraping is to navigate through all the categories on the navigation bar, then, for each category, scrape the existing articles in each page by navigating through a desired number of pages by indicating it in a parameter named `numpages` existing in sloc: `hespress.py:20` & `hibapress.py:16`.  \n",
    "\n",
    "> **Items used in the scraping process are:**\n",
    "*    HesArticle.\n",
    "*    HesComment.\n",
    "*    HibArticle.\n",
    "*    HibComment.  \n",
    "They are indicated in `items.py`.\n",
    "\n",
    "> **Pipelines used in the scraping process are:**\n",
    "*    HesArticlePipeline.\n",
    "*    HibPipeline.  \n",
    "They are enabled in the following setting parameter named `ITEM_PIPELINES` existing in sloc: `settings.py:67`.  \n",
    "The two pipeline classes are written in `pipelines.py`.\n",
    "\n",
    "> **XPATH expressions are written in a config file: `xpath_cfg.py`**  .\n",
    "\n",
    "\n",
    "### 1.   The data & metadata of each article to scrape are of the  following types:\n",
    "\n",
    "*   Article ID.\n",
    "*   Author.\n",
    "*   Writer or article creator/publisher. ( For *Hibapress* only )\n",
    "*   Category.\n",
    "*   Number of comments.\n",
    "*   Date.\n",
    "*   Title.\n",
    "*   Article link.\n",
    "\n",
    "### 2.   The data & metadata of each comment in each article to scrape are of the following types:\n",
    "*   Article ID.\n",
    "*   Comment number.\n",
    "*   Comment content.\n",
    "*   Comment author.\n",
    "*   Comment date.\n",
    "*   Comment appreciation. ( for *Hespress* only )\n",
    "\n",
    "### For each website, there are two types of output csv files: \n",
    "*   Articles csv file.\n",
    "*   Comments csv file.  \n",
    "\n",
    "> The output files are created in a folder named `output`.\n",
    "\n",
    "  \n",
    "    \n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L8Tlza4tT8jG"
   },
   "source": [
    "# Running the script\n",
    "\n",
    "> This project uses the Scrapy v1.6.0.\n",
    "\n",
    "In terminal, run this command to run *hibapress* spider:\n",
    "\n",
    "```\n",
    "$ scrapy crawl hibapress\n",
    "```\n",
    "or this, to run the *hespress* spider: \n",
    "```\n",
    "$ scrapy crawl hespress\n",
    "```\n",
    "\n",
    "> The integer values assigned to pipeline classes in the sloc `settings.py:67` setting determine the order in which they run: items go through from lower valued to higher valued classes. The pipeline class associated to the spider to be run must have the lowest integer value.  \n",
    "> In `settings.py:67`\n",
    "```\n",
    "67: ITEM_PIPELINES = {\n",
    "68:    'WebCrawler.pipelines.HesArticlePipeline': 200,\n",
    "69:   'WebCrawler.pipelines.HibPipeline': 300,\n",
    "70: }\n",
    "``` \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8F-fAqLPyUu3"
   },
   "source": [
    "# TO-DO list: \n",
    "\n",
    "### ------ For *Hibapress*: \n",
    "For *Hibapress*, the most of the author names are scraped correctly. But there's always an issue regarding this type of data: The author's name does not explicitly exist in a classified or identified HTML tag that contains the author's name, nor, can be found in a recognizable/repeated HTML tags pattern.\n",
    "For the overwhelming majority of the articles, the author's name does exist under two main formats:\n",
    "\n",
    "### 1.   1st format: \n",
    "\n",
    "```\n",
    "<input type=\"hidden\" name=\"_wp_http_referer\" value=\"/details-XXXXXX.html\">\n",
    "<p> -- The author's name -- </p>\n",
    "<p> 1st paragraph of the article body </p>\n",
    "<p> 2nd paragraph of the article body </p>\n",
    "...\n",
    "```\n",
    "\n",
    "### 2.   2nd format: \n",
    "\n",
    "```\n",
    "<input type=\"hidden\" name=\"_wp_http_referer\" value=\"/details-XXXXXX.html\">\n",
    "<span style=\"color:#000ff\"> -- The author's name -- </span>\n",
    "<p> 1st paragraph of the article body </p>\n",
    "<p> 2nd paragraph of the article body </p>\n",
    "...\n",
    "```\n",
    "\n",
    "*    There are also plenty of other formats that are combinations of the two formats mentioned. Thoses combinations are processed by multiple conditions in the **XPATH** expressions used.\n",
    "*    Sometimes the author's name is in multiple nested `div` & `span` tags with different classnames & ids. \n",
    "*    Also, the author's name may be missing in some articles. In this case, some conditions in the **XPATH** expressions are used to handle this problem, and avoid scraping the ***1st paragraph of the article body***. ( until now, the **XPATH** expressions can only reduce the number of articles body paragraphs being scraped as author's name using string conditions: ***length, contains ...etc.***).\n",
    "\n",
    "\n",
    "> *The most of articles having this problem are of the category: شؤون دينية which happens that plenty of articles of this category have missing author names.*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nXUOoetYHpsd"
   },
   "source": [
    "Here's some samples that illustrate the author's name problem that causes ambiguity:  \n",
    "\n",
    "*   https://ar.hibapress.com/details-238237.html\n",
    "*   https://ar.hibapress.com/details-248606.html\n",
    "*   https://ar.hibapress.com/details-251662.html\n",
    "*   https://ar.hibapress.com/details-239701.html\n",
    "*   https://ar.hibapress.com/details-250679.html\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "  \n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzRsOueDWqm-"
   },
   "source": [
    "# Extras:\n",
    "There's two additional scripts:\n",
    "\n",
    "\n",
    "1.   `hesdate_parser.py`.\n",
    "2.   `hibdate_parser.py`.\n",
    "\n",
    "- The 1st script parse ***dates*** in ***Hespress*** output csv files and rewrite them in a standard format.\n",
    "- The 2nd script parse ***dates*** in ***Hibapress*** output csv files and rewrite them in a standard format.\n",
    "\n",
    "\n",
    "\n",
    "> Theses two following commands can be used to run the scripts separately:\n",
    "\n",
    "\n",
    "```\n",
    "$ python hesdate_parser.py\n",
    "```\n",
    "and, \n",
    "```\n",
    "$ python hibdate_parser.py\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eZ11g7CKZ53V"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled15.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
